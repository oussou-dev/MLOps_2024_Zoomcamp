{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBTy-1OJY9VU"
      },
      "source": [
        "# **Homework**\n",
        "\n",
        "The goal of this homework is to get familiar with MLflow, the tool for experiment tracking and model management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_rY_CwmZBNn",
        "outputId": "b844d511-e3a2-4dca-d9b0-2b06a396f269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6EecdtJY9VY"
      },
      "source": [
        "## **Q1. Install MLflow**\n",
        "\n",
        "To get started with MLflow you'll need to install the MLflow Python package.\n",
        "\n",
        "For this we recommend creating a separate Python environment, for example, you can use conda environments, and then install the package there with pip or conda.\n",
        "\n",
        "Once you installed the package, run the command `mlflow --version` and check the output.\n",
        "\n",
        "What's the version that you have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "io10attPbZAF",
        "outputId": "f7763c37-3f9c-4544-a6eb-76d6fe0728b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.13.0-py3-none-any.whl (25.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
            "Collecting opentelemetry-api<3,>=1.0.0 (from mlflow)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk<3,>=1.0.0 (from mlflow)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.0)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.30)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<23 (from mlflow)\n",
            "  Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.0.0->mlflow)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<3,>=1.0.0->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow) (1.14.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aniso8601, smmap, querystring-parser, opentelemetry-semantic-conventions, Mako, importlib-metadata, gunicorn, graphql-core, deprecated, opentelemetry-api, graphql-relay, gitdb, docker, alembic, opentelemetry-sdk, graphene, gitpython, mlflow\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 aniso8601-9.0.1 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 importlib-metadata-7.0.0 mlflow-2.13.0 opentelemetry-api-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjEY_mu9Y9Va",
        "outputId": "31e632f3-dea1-4ec6-9781-00f4e187931c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlflow, version 2.13.0\n"
          ]
        }
      ],
      "source": [
        "!mlflow --version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi9drKlVY9Vb"
      },
      "source": [
        "## **Q2. Download and preprocess the data**\n",
        "\n",
        "We'll use the Green Taxi Trip Records dataset to predict the duration of each trip.\n",
        "\n",
        "Download the data for January, February and March 2023 in parquet format from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
        "\n",
        "Use the script preprocess_data.py located in the folder [homework](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/cohorts/2024/02-experiment-tracking/homework) to preprocess the data.\n",
        "\n",
        "The script will:\n",
        "\n",
        "- load the data from the folder `<TAXI_DATA_FOLDER>` (the folder where you have downloaded the data),\n",
        "- fit a `DictVectorizer` on the training set (January 2023 data),\n",
        "- save the preprocessed datasets and the `DictVectorizer` to disk.\n",
        "\n",
        "Your task is to download the datasets and then execute this command:\n",
        "\n",
        "```\n",
        "python preprocess_data.py --raw_data_path <TAXI_DATA_FOLDER> --dest_path ./output\n",
        "```\n",
        "\n",
        "Tip: go to `02-experiment-tracking/homework/` folder before executing the command and change the value of `<TAXI_DATA_FOLDER>` to the location where you saved the data.\n",
        "\n",
        "How many files were saved to `OUTPUT_FOLDER`?\n",
        "\n",
        "- 1\n",
        "- 3\n",
        "- 4\n",
        "- 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7aHaWVvY9Vc"
      },
      "outputs": [],
      "source": [
        "!python preprocess_data.py --raw_data_path /content/drive/MyDrive/Zoomcamp_MLOps_2024/data --dest_path /content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCcnzwM1Y9Ve",
        "outputId": "b809e9aa-835b-4d08-c793-901f8e59c500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dv.pkl  test.pkl  train.pkl  val.pkl\n"
          ]
        }
      ],
      "source": [
        "ls /content/output # ls -1 | wc -l && ls /content/output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytAoufifY9Vf"
      },
      "source": [
        "## **Q3. Train a model with autolog**\n",
        "\n",
        "We will train a `RandomForestRegressor` (from Scikit-Learn) on the taxi dataset.\n",
        "\n",
        "We have prepared the training script `train.py` for this exercise, which can be also found in the folder `homework`.\n",
        "\n",
        "The script will:\n",
        "\n",
        "- load the datasets produced by the previous step,\n",
        "- train the model on the training set,\n",
        "- calculate the RMSE score on the validation set.\n",
        "\n",
        "Your task is to modify the script to enable autologging with MLflow, execute the script and then launch the MLflow UI to check that the experiment run was properly tracked.\n",
        "\n",
        "Tip 1: don't forget to wrap the training code `with a with mlflow.start_run()`: statement as we showed in the videos.\n",
        "\n",
        "Tip 2: don't modify the hyperparameters of the model to make sure that the training will finish quickly.\n",
        "\n",
        "What is the value of the `min_samples_split parameter`:\n",
        "\n",
        "- 2\n",
        "- 4\n",
        "- 8\n",
        "- 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onr57STpdJTI"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDYsNx-ZY9Vg",
        "outputId": "cc62af6a-ebf6-400f-a00e-2db4ccbc65f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the ngrok authtoken: \n",
            "MLflow Tracking UI: https://07c9-34-80-84-214.ngrok-free.app\n",
            "2024/05/29 22:35:24 INFO mlflow.tracking.fluent: Experiment with name 'mlops-zoomcamp-week-2' does not exist. Creating a new experiment.\n",
            "2024/05/29 22:35:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
            "t=2024-05-29T22:35:32+0000 lvl=warn msg=\"failed to open private leg\" id=0403195ace62 privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2024-05-29T22:35:36+0000 lvl=warn msg=\"failed to open private leg\" id=13bb8027c8a3 privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "2024/05/29 22:35:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
            "Min samples split: 2\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhjg9qTBf7V8"
      },
      "source": [
        "## **Q4. Launch the tracking server locally**\n",
        "\n",
        "Now we want to manage the entire lifecycle of our ML model. In this step, you'll need to launch a tracking server. This way we will also have access to the model registry.\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "- launch the tracking server on your local machine,\n",
        "- select a SQLite db for the backend store and a folder called artifacts for the artifacts store.\n",
        "\n",
        "You should keep the tracking server running to work on the next two exercises that use the server.\n",
        "\n",
        "In addition to `backend-store-uri`, what else do you need to pass to properly configure the server?\n",
        "\n",
        "- `default-artifact-root`\n",
        "- `serve-artifacts`\n",
        "- `artifacts-only`\n",
        "- `artifacts-destination`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmMZ6jVgg-GU"
      },
      "outputs": [],
      "source": [
        "# run MLFlow and save all the artifacts and metadata in an SQLite backend\n",
        "#=> mlflow ui --backend-store-uri sqlite:///mlflow.db`\n",
        "\n",
        "# to properly configure the server.\n",
        "#=> default-artifact-root  This is necessary and must be specified if you are using a local path or a non-default storage mechanism for artifacts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5md3sBjhUMB"
      },
      "source": [
        "## **Q5. Tune model hyperparameters**\n",
        "\n",
        "Now let's try to reduce the validation error by tuning the hyperparameters of the **RandomForestRegressor** using **hyperopt**. We have prepared the script **hpo.py** for this exercise.\n",
        "\n",
        "Your task is to modify the script **hpo.py** and make sure that the validation RMSE is logged to the tracking server for each run of the hyperparameter optimization (you will need to add a few lines of code to the objective function) and run the script without passing any parameters.\n",
        "\n",
        "After that, open UI and explore the runs from the experiment called **random-forest-hyperopt** to answer the question below.\n",
        "\n",
        "Note: Don't use autologging for this exercise.\n",
        "\n",
        "The idea is to just log the information that you need to answer the question below, including:\n",
        "\n",
        "- the list of hyperparameters that are passed to the **objective** function during the optimization,\n",
        "- the RMSE obtained on the validation set (February 2023 data).\n",
        "\n",
        "What's the best validation RMSE that you got?\n",
        "\n",
        "- 4.817\n",
        "- 5.335\n",
        "- 5.818\n",
        "- 6.336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ut73-Thz4Y",
        "outputId": "d84a483f-9869-4f0c-8d03-9108f1e2ad7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the ngrok authtoken: \n",
            "MLflow Tracking UI: https://d68b-34-80-84-214.ngrok-free.app\n",
            "2024/05/29 22:53:42 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-hyperopt' does not exist. Creating a new experiment.\n",
            "100% 15/15 [01:42<00:00,  6.84s/trial, best loss: 5.335419588556921]\n"
          ]
        }
      ],
      "source": [
        "!python hpo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoVpr_1FkUNy"
      },
      "source": [
        "## **Q6. Promote the best model to the model registry**\n",
        "\n",
        "The results from the hyperparameter optimization are quite good. So, we can assume that we are ready to test some of these models in production. In this exercise, you'll promote the best model to the model registry. We have prepared a script called **register_model.py**, which will check the results from the previous step and select the top 5 runs. After that, it will calculate the RMSE of those models on the test set (March 2023 data) and save the results to a new experiment called **random-forest-best-models**.\n",
        "\n",
        "Your task is to update the script **register_model.py** so that it selects the model with the lowest RMSE on the test set and registers it to the model registry.\n",
        "\n",
        "Tip 1: you can use the method **search_runs** from the **MlflowClient** to get the model with the lowest RMSE,\n",
        "\n",
        "Tip 2: to register the model you can use the method **mlflow.register_model** and you will need to pass the right **model_uri** in the form of a string that looks like this: **\"runs:/<RUN_ID>/model\"**, and the name of the model (make sure to choose a good one!).\n",
        "\n",
        "What is the test RMSE of the best model?\n",
        "\n",
        "- 5.060\n",
        "- 5.567\n",
        "- 6.061\n",
        "- 6.568\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrdnJ98klIiJ",
        "outputId": "a0012701-e935-4bd5-de9a-7966139172d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the ngrok authtoken: \n",
            "MLflow Tracking UI: https://09b9-34-80-84-214.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "!python register_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NtvM5TD3luxm"
      },
      "outputs": [],
      "source": [
        "# 5.567"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
